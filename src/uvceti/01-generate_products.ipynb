{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "import gPhoton\n",
    "from gPhoton.MCUtils import print_inline\n",
    "from gPhoton import PhotonPipe\n",
    "import numpy as np\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the modified version of PhotonPipe is in use:\n",
    "if not gPhoton.__version__ == '1.28.9_nomask':\n",
    "    raise RuntimeError('Incorrect version of PhotonPipe. You must use the branch'\n",
    "                      '\"1.28.9_nomask\" available in the gPhoton GitHub repository.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function definitions that accompany this notebook tutorial.\n",
    "nb_funcdef_file = \"function_defs.py\"\n",
    "if os.path.isfile(nb_funcdef_file):\n",
    "    from function_defs import listdir_contains, write_image, write_movie, make_lightcurve\n",
    "else:\n",
    "    raise IOError(\"Could not find function definition file '\" + nb_funcdef_file + \"' that goes with this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sky position of UV Ceti from GAIA DR2\n",
    "# Precision doesn't matter here because we'll dial it in later from the data.\n",
    "hhmmss = SkyCoord('01h39m01.6334059022s', '-17d57m01.121866655s', frame='icrs')\n",
    "skypos = (hhmmss.ra.degree, hhmmss.dec.degree)\n",
    "print(\"Gaia RA, Dec (J2015.5): \" + repr(skypos))\n",
    "# This is closer to the position in the GALEX catalog, so we'll start with this coordinate\n",
    "# (both in degrees).\n",
    "skypos = (24.76279, -17.94948)\n",
    "print(\"Using RA, Dec values of \" + repr(skypos) + \" degrees.\")\n",
    "# Best available distance to UV Ceti from GAIA DR2\n",
    "parallax = 372.1631 # mas\n",
    "distance = 1/(372.1631/1000) # parsecs\n",
    "print('Distance: {d} +/- 0.002 pc'.format(d=round(distance,3)))\n",
    "%store skypos\n",
    "%store distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data volume.\n",
    "data_directory = './raw_files/'\n",
    "# Check that the data volume is available, if not, create the directory path.\n",
    "if not os.path.exists(data_directory):\n",
    "    os.makedirs(data_directory)\n",
    "# Store the directory for use in other notebooks.\n",
    "%store data_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the locations of -raw6 and -scst files corresponding to a particular location.\n",
    "# These will be downloaded and used to create the light curves we analyze.\n",
    "url = \"https://mastcomp.stsci.edu/portal/Mashup/MashupQuery.asmx/GalexPhotonListQueryTest?query=exec spGetRawUrls @ra={ra}, @dec={dec}, @radius={radius}&format=extjs\".format(\n",
    "        ra=skypos[0], dec=skypos[1], radius=10)\n",
    "raw_urls = [foo[-1] for foo in gPhoton.gQuery.getArray(url)]\n",
    "n_raw_urls_expected = 48\n",
    "if len(raw_urls) != n_raw_urls_expected: # regression test\n",
    "    raise ValueError(\"Expected \" + str(n_raw_urls_expected) + \" raw_urls but found \" + str(len(raw_urls)))\n",
    "# If you want to see the URLs that contain the raw data, set the print_out_urls value to True\n",
    "print_out_urls = False\n",
    "if print_out_urls:\n",
    "    for raw_url in raw_urls:\n",
    "            print(raw_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will download the raw files.  Note, this can take a while the first time (20 minutes or\n",
    "# longer), but only needs to be done one time, future runs of this notebook will not\n",
    "# re-download the files if it finds them in the directory defined in \"data_directory\" above.\n",
    "print('Downloading the raw data files. This might take awhile.')\n",
    "for raw_url in raw_urls:\n",
    "    filepath = '{data_directory}{filename}'.format(data_directory=data_directory, filename=raw_url.split('/')[-1])\n",
    "    if not os.path.exists(filepath):\n",
    "        print_inline('Downloading {url} to {filepath}'.format(url=raw_url, filepath=filepath))\n",
    "        r = requests.get(raw_url)\n",
    "        with open(filepath, 'wb') as fd:\n",
    "            for chunk in r.iter_content(chunk_size=128):\n",
    "                fd.write(chunk)\n",
    "print(\"\\nAll files downloaded or found on disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regenerate the calibrated photon list files.  Note: this can take quite a while, sometimes hours.\n",
    "print('Regenerating the calibrated photon files. This might take a long time.')\n",
    "raw6_fuv = listdir_contains(data_directory,'fd-raw6')\n",
    "for raw6 in raw6_fuv:\n",
    "    if os.path.exists(raw6[:-13]+'.csv'):\n",
    "        continue\n",
    "    PhotonPipe.photonpipe(raw6[:-13],'FUV',raw6file=raw6,scstfile=raw6.replace('fd-raw6','scst'),verbose=2)\n",
    "print_inline('Done.')\n",
    "\n",
    "raw6_nuv = listdir_contains(data_directory,'nd-raw6')\n",
    "for raw6 in raw6_nuv:\n",
    "    if os.path.exists(raw6[:-13]+'.csv'):\n",
    "        continue\n",
    "    PhotonPipe.photonpipe(raw6[:-13],'NUV',raw6file=raw6,scstfile=raw6.replace('nd-raw6','scst'),verbose=2)\n",
    "print_inline('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all of the photon data exist.\n",
    "photon_files = {'NUV':listdir_contains(data_directory,'nd.csv'),\n",
    "                'FUV':listdir_contains(data_directory,'fd.csv')}\n",
    "for band in ['NUV','FUV']:\n",
    "    n_expected = 14\n",
    "    if len(photon_files[band]) != n_expected:\n",
    "        print(len(photon_files[band]))\n",
    "        raise ValueError(\"Did not find expected number (\" + str(n_expected) + \") of the csv files for band \" + band +\n",
    "                             \".  Found \" + str(len(photon_files[band])) + \" instead.\")\n",
    "    print('There are {n} {band} observations available, as expected.'.format(n=len(photon_files[band]), band=band))\n",
    "    # Set the variable below to True if you want to print the names of the photon event .csv files.\n",
    "    print_found_csv = False\n",
    "    if print_found_csv:\n",
    "        for photon_file in photon_files[band]:\n",
    "            print('\\t{pf}'.format(pf=photon_file.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the FITS image files.  Only the first nine visits are created, because they are the deepest exposure times,\n",
    "# the tenth visit is not shown in plots.  Set \"overwrite\" to False to avoid re-creating FITS files that already exist.\n",
    "n_visits = 9\n",
    "for band in ['FUV','NUV']:\n",
    "    for i in np.arange(n_visits):\n",
    "        print('FITS image in {b}: Visit {i}'.format(b=band, i=i+1))\n",
    "        write_image(photon_files[band][i], band, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create light curves with 30-second sampling.  This is the initial creation of the light curves.  It can take a while,\n",
    "# sometimes hours.\n",
    "for i in np.arange(len(photon_files['NUV'])):\n",
    "    print(\"Creating light curve files for visit # \" + str(i+1) + ' / ' + str(len(photon_files['NUV'])) + \"...\")\n",
    "    lc_nuv = make_lightcurve(photon_files['NUV'][i], 'NUV', stepsz=30., skypos=skypos, makefile=False)\n",
    "    try:\n",
    "        lc_fuv = make_lightcurve(photon_files['NUV'][i].replace('nd','fd'), 'FUV', stepsz=30.,\n",
    "                             skypos=skypos, fixed_t0=lc_nuv['t0'].min(), makefile=False)\n",
    "    except:\n",
    "        print('Skipping: No FUV data?')\n",
    "        continue\n",
    "    tranges = zip(lc_fuv['t0'], lc_fuv['t1'])\n",
    "    write_movie(photon_files['NUV'][i].replace('nd','fd'), 'FUV', tranges)\n",
    "    tranges = zip(lc_nuv['t0'], lc_nuv['t1'])\n",
    "    write_movie(photon_files['NUV'][i], 'NUV', tranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
