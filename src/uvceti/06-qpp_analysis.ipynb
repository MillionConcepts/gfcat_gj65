{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.timeseries import LombScargle\n",
    "import gPhoton.dbasetools as dt\n",
    "import gPhoton.galextools as gt\n",
    "import gPhoton.MCUtils as mc\n",
    "from gPhoton.gphoton_utils import read_lc\n",
    "from gPhoton import gAperture\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import savgol_filter\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function definitions that accompany this notebook tutorial.\n",
    "nb_funcdef_file = \"function_defs.py\"\n",
    "if os.path.isfile(nb_funcdef_file):\n",
    "    from function_defs import make_lightcurve, listdir_contains\n",
    "else:\n",
    "    raise IOError(\"Could not find function definition file '\" + nb_funcdef_file + \"' that goes with this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the output directory.  Note: this assumes you've run the \"generate_products\" notebook already.  If not you\n",
    "# will need to specify the location of the products made from the \"generate_products\" notebook.\n",
    "%store -r data_directory\n",
    "# If you have not run the \"generate_products\" notebook during this session, uncomment the line below and specify\n",
    "# the location of the output products.\n",
    "#data_directory = \"./raw_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the skypos parameter.  Note: this assumes you've run the \"generate_products\" notebook already.  If not you\n",
    "# will need to specify the sky position to use.\n",
    "%store -r skypos\n",
    "# If you have not run the \"generate_products\" notebook during this session, uncomment the line below and specify\n",
    "# the sky position in degrees.\n",
    "#skypos = (24.76279, -17.94948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the photon files.\n",
    "photon_files = {'NUV':listdir_contains(data_directory,'nd.csv'),\n",
    "                'FUV':listdir_contains(data_directory,'fd.csv')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this flare has such a large count rate, we can make a 5-second light curve to explore it's shape in detail.\n",
    "# Flare #8 is in Visit #5 (index 4 in our array of .csv files.) Note that if you already have\n",
    "# created the 5-second light curve files previously this will not overwrite them.\n",
    "lc_nuv = make_lightcurve(photon_files['NUV'][4], 'NUV', stepsz=5., skypos=skypos, quiet=False, makefile=False)\n",
    "lc_fuv = make_lightcurve(photon_files['FUV'][4], 'FUV', stepsz=5., skypos=skypos, fixed_t0=lc_nuv['t0'].min(),\n",
    "                             quiet=True, makefile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is visual evidence of in-flare variability, let's remove a simple flare shape and make a quick periodorgram\n",
    "# of the residuals.\n",
    "times_fuv = np.asarray(lc_fuv[\"t0\"]-min(lc_fuv[\"t0\"]))\n",
    "times_nuv = np.asarray(lc_nuv[\"t0\"]-min(lc_nuv[\"t0\"]))\n",
    "where_flare_fuv = np.where((times_fuv > 1200.) & (np.isfinite(lc_fuv['flux_apcorrected'])))[0]\n",
    "where_flare_nuv = np.where((times_nuv > 1200.) * (np.isfinite(lc_nuv['flux_apcorrected'])))[0]\n",
    "flare_times_fuv = times_fuv[where_flare_fuv]\n",
    "flare_fluxes_fuv = np.asarray(lc_fuv[\"flux_apcorrected\"])[where_flare_fuv]\n",
    "flare_flux_errs_fuv = np.asarray(lc_fuv[\"flux_err\"])[where_flare_fuv]\n",
    "flare_times_nuv = times_nuv[where_flare_nuv]\n",
    "flare_fluxes_nuv = np.asarray(lc_nuv[\"flux_apcorrected\"])[where_flare_nuv]\n",
    "flare_flux_errs_nuv = np.asarray(lc_nuv[\"flux_err\"])[where_flare_nuv]\n",
    "\n",
    "# Fit a simple shape for the flare, let's use a Savitzky-Golay filter.\n",
    "fluxfitted_fuv = savgol_filter(flare_fluxes_fuv, 21, 3)\n",
    "fluxfitted_nuv = savgol_filter(flare_fluxes_nuv, 21, 3)\n",
    "                           \n",
    "# Let's do a periodagram to check for any strong periodic signals.\n",
    "lombscarg_fuv = LombScargle(flare_times_fuv, flare_fluxes_fuv-fluxfitted_fuv)\n",
    "frequency_fuv, power_fuv = lombscarg_fuv.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "lombscarg_nuv = LombScargle(flare_times_nuv, flare_fluxes_nuv-fluxfitted_nuv)\n",
    "frequency_nuv, power_nuv = lombscarg_nuv.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "\n",
    "# Let's make a plot of the flare region of the light curve we are looking at (left column).\n",
    "# We'll also show the quick periodgrams we made (right column).\n",
    "fig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2, 3, figsize=(16,14))\n",
    "ax1.errorbar(flare_times_fuv, flare_fluxes_fuv, yerr=flare_flux_errs_fuv,\n",
    "             fmt='-b', label=\"FUV\")\n",
    "ax1.plot(flare_times_fuv, fluxfitted_fuv, '-r', linewidth=2)\n",
    "ax2.plot(flare_times_fuv, flare_fluxes_fuv - fluxfitted_fuv, '-b', label=\"FUV Residual\")\n",
    "ax3.plot(1./frequency_fuv, power_fuv, '-b')\n",
    "ax4.errorbar(flare_times_nuv, flare_fluxes_nuv, yerr=flare_flux_errs_nuv,\n",
    "             fmt='-k', label=\"NUV\")\n",
    "ax4.plot(flare_times_nuv, fluxfitted_nuv, '-r', linewidth=2)\n",
    "ax5.plot(flare_times_nuv, flare_fluxes_nuv - fluxfitted_nuv, '-k', label=\"NUV Residual\")\n",
    "ax6.plot(1./frequency_nuv, power_nuv, '-k')\n",
    "# Set axis ranges appropriately.\n",
    "ax1.set_xlim(1200., 1800.)\n",
    "ax4.set_xlim(1200., 1800.)\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax4.legend()\n",
    "ax5.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the peak frequency and power?\n",
    "# Convert to numpy arrays to make use of the where() function.\n",
    "frequency_fuv = np.asarray(frequency_fuv)\n",
    "frequency_nuv = np.asarray(frequency_nuv)\n",
    "power_fuv = np.asarray(power_fuv)\n",
    "power_nuv = np.asarray(power_nuv)\n",
    "\n",
    "print(\"FUV Max Period = \" + str(1./frequency_fuv[np.argmax(power_fuv)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_fuv.false_alarm_probability(power_fuv.max())))\n",
    "print(\"NUV Max Period = \" + str(1./frequency_nuv[np.argmax(power_nuv)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "     str(lombscarg_nuv.false_alarm_probability(power_nuv.max())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both bands show VERY strong signals with identical periods.  A more careful analysis is in order.  But before then, let's check other parts of the light curve, and other stars in the same field-of-view, to see if they have similarly strong signals anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We see evidence of in-flare pulsations, but is there any evidence of out-of-flare pulsations?\n",
    "# Let's zoom-in on the long stretch of time before the large flare begins.\n",
    "where_preflare_fuv = np.where((times_fuv > 500.) & (times_fuv < 1100.))[0]\n",
    "where_preflare_nuv = np.where((times_nuv > 500.) & (times_nuv < 1100.))[0]\n",
    "preflare_times_fuv = times_fuv[where_preflare_fuv]\n",
    "preflare_fluxes_fuv = np.asarray(lc_fuv[\"flux_apcorrected\"])[where_preflare_fuv]\n",
    "preflare_flux_errs_fuv = np.asarray(lc_fuv[\"flux_err\"])[where_preflare_fuv]\n",
    "preflare_times_nuv = times_nuv[where_preflare_nuv]\n",
    "preflare_fluxes_nuv = np.asarray(lc_nuv[\"flux_apcorrected\"])[where_preflare_nuv]\n",
    "preflare_flux_errs_nuv = np.asarray(lc_nuv[\"flux_err\"])[where_preflare_nuv]\n",
    "\n",
    "# Let's do a periodagram to check for any strong periodic signals.\n",
    "lombscarg_fuv = LombScargle(preflare_times_fuv, preflare_fluxes_fuv)\n",
    "frequency_fuv, power_fuv = lombscarg_fuv.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "lombscarg_nuv = LombScargle(preflare_times_nuv, preflare_fluxes_nuv)\n",
    "frequency_nuv, power_nuv = lombscarg_nuv.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "\n",
    "# Let's make a plot of the pre-flare region of the light curve we are looking at (left column).\n",
    "# We'll also show the quick periodgrams we made (right column).\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(16,14))\n",
    "ax1.errorbar(preflare_times_fuv, preflare_fluxes_fuv, yerr=preflare_flux_errs_fuv,\n",
    "             fmt='bo', label=\"FUV, Pre-Flare\")\n",
    "ax3.errorbar(preflare_times_nuv, preflare_fluxes_nuv, yerr=preflare_flux_errs_nuv,\n",
    "             fmt='ko', label=\"NUV, Pre-Flare\")\n",
    "ax2.plot(1./frequency_fuv, power_fuv, '-b')\n",
    "ax4.plot(1./frequency_nuv, power_nuv, '-k')\n",
    "# Set axis ranges appropriately.\n",
    "ax1.set_xlim(500., 1100.)\n",
    "ax3.set_xlim(500., 1100.)\n",
    "ax1.set_ylim(-1E-15, 5.5E-15)\n",
    "ax3.set_ylim(0, 3.5E-15)\n",
    "ax1.legend()\n",
    "ax3.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the peak frequency and power?\n",
    "# Convert to numpy arrays to make use of the where() function.\n",
    "frequency_fuv = np.asarray(frequency_fuv)\n",
    "frequency_nuv = np.asarray(frequency_nuv)\n",
    "power_fuv = np.asarray(power_fuv)\n",
    "power_nuv = np.asarray(power_nuv)\n",
    "\n",
    "print(\"FUV Max Period = \" + str(1./frequency_fuv[np.argmax(power_fuv)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_fuv.false_alarm_probability(power_fuv.max())))\n",
    "print(\"NUV Max Period = \" + str(1./frequency_nuv[np.argmax(power_nuv)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "     str(lombscarg_nuv.false_alarm_probability(power_nuv.max())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strongest peaks have >99% false alarm probability, so there's no periodic signal happening before the flare starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One final test for GJ 65 itself: let's check what the periodgram of the spacecraft boresight looks like, to check\n",
    "# if this signal might be induced as part of the dither pattern.  This can be tracked in gPhoton results with the\n",
    "# 'detrad' parameter.  We will also make sure the variability is not correlated with the \n",
    "# effective exposure time within each time bin through the 'expt' parameter.\n",
    "flare_detrads = np.asarray(lc_nuv[\"detrad\"])[where_flare_nuv]\n",
    "flare_expts = np.asarray(lc_nuv[\"expt\"])[where_flare_nuv]\n",
    "\n",
    "# Let's do a periodagram to check for any strong periodic signals.\n",
    "lombscarg_nuv_detrad = LombScargle(flare_times_nuv, flare_detrads)\n",
    "frequency_nuv_detrad, power_nuv_detrad = lombscarg_nuv_detrad.autopower(\n",
    "    minimum_frequency=0.01, maximum_frequency=0.1, samples_per_peak=20)\n",
    "lombscarg_nuv_expt = LombScargle(flare_times_nuv, flare_expts)\n",
    "frequency_nuv_expt, power_nuv_expt = lombscarg_nuv_expt.autopower(\n",
    "    minimum_frequency=0.01, maximum_frequency=0.1, samples_per_peak=20)\n",
    "\n",
    "# Let's make a plot of these parameters over time (left column).\n",
    "# We'll also show the quick periodgrams we made (right column).\n",
    "fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2, 2, figsize=(16,14))\n",
    "ax1.plot(flare_times_nuv, flare_detrads, 'bo')\n",
    "ax1.set_ylabel(\"Dist. From Center\")\n",
    "ax3.plot(flare_times_nuv, flare_expts, 'ko')\n",
    "ax3.set_ylabel(\"Exp. Times (sec)\")\n",
    "ax2.plot(1./frequency_nuv_detrad, power_nuv_detrad, '-b')\n",
    "ax4.plot(1./frequency_nuv_expt, power_nuv_expt, '-k')\n",
    "# Set axis ranges appropriately.\n",
    "ax1.set_xlim(1200., 1800.)\n",
    "ax3.set_xlim(1200., 1800.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the peak frequency and power?\n",
    "# Convert to numpy arrays to make use of the where() function.\n",
    "frequency_nuv_detrad = np.asarray(frequency_nuv_detrad)\n",
    "frequency_nuv_expt = np.asarray(frequency_nuv_expt)\n",
    "power_nuv_detrad = np.asarray(power_nuv_detrad)\n",
    "power_nuv_expt = np.asarray(power_nuv_expt)\n",
    "\n",
    "print(\"NUV Detrad Max Period = \" + str(1./frequency_nuv_detrad[np.argmax(power_nuv_detrad)]) +\n",
    "      \" sec with FAP = \" +\n",
    "      str(lombscarg_nuv_detrad.false_alarm_probability(power_nuv_detrad.max())))\n",
    "print(\"NUV Exptime Max Period = \" +\n",
    "      str(1./frequency_nuv_expt[np.argmax(power_nuv_expt)]) + \" sec\" + \" with FAP = \" +\n",
    "     str(lombscarg_nuv_expt.false_alarm_probability(power_nuv_expt.max())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strongest peaks have >99% false alarm probability, so there's no periodic signal due to dither pattern of effective exposure times of the bins within the frequency range we searched with any significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In fact, let's change the periodogram range to zoom in on the clearly periodic dither pattern (as expected).\n",
    "flare_detrads = np.asarray(lc_nuv[\"detrad\"])[where_flare_nuv]\n",
    "flare_expts = np.asarray(lc_nuv[\"expt\"])[where_flare_nuv]\n",
    "\n",
    "# Let's do a periodagram to check for any strong periodic signals.\n",
    "lombscarg_nuv_detrad = LombScargle(flare_times_nuv, flare_detrads)\n",
    "frequency_nuv_detrad, power_nuv_detrad = lombscarg_nuv_detrad.autopower(\n",
    "    minimum_frequency=0.005, maximum_frequency=0.02, samples_per_peak=20)\n",
    "\n",
    "# Let's make a plot of these parameters over time (left column).\n",
    "# We'll also show the quick periodgrams we made (right column).\n",
    "fig, (ax1,ax2) = plt.subplots(2, 1, figsize=(16,14))\n",
    "ax1.plot(flare_times_nuv, flare_detrads, 'bo')\n",
    "ax1.set_ylabel(\"Dist. From Center\")\n",
    "ax2.plot(1./frequency_nuv_detrad, power_nuv_detrad, '-ob')\n",
    "ax1.set_title(\"Dither pattern frequency = \" + str(1./frequency_nuv_detrad[np.argmax(power_nuv_detrad)]))\n",
    "# Set axis ranges appropriately.\n",
    "ax1.set_xlim(1200., 1800.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also check nearby stars to see if any of them show periodic pulsations during the same\n",
    "# time period.  First let's look for nearby, known GALEX sources.\n",
    "# This line will return all GALEX MCAT sources within 0.1 degrees of our coordinate, down to\n",
    "# a magnitude of 21.\n",
    "out = dt.get_mags('NUV', skypos[0], skypos[1], 0.1, 21.)\n",
    "sources = np.asarray(dt.parse_unique_sources(out['ra'], out['dec']))\n",
    "distances = np.asarray([mc.angularSeparation(skypos[0], skypos[1], x, y)*3600. for x,y in sources])\n",
    "sort_indexes = np.argsort(distances)\n",
    "sources = sources[sort_indexes]\n",
    "distances = distances[sort_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's identify the three closest sources that are not very close to GJ 65 (to avoid selecting\n",
    "# the star itself.)  We'll look for the closest sources, but skip over sources that are\n",
    "# very close to our target in case it is GJ 65 itself!\n",
    "closest_sources = []\n",
    "n_found = 0\n",
    "for (ra, dec), dist in zip(sources, distances):\n",
    "    # If within a GALEX spatial resolution element, ignore (probably GJ 65 itself).\n",
    "    if dist > 6.:\n",
    "        closest_sources.append({'ra':ra, 'dec':dec, 'dist':dist})\n",
    "        n_found += 1\n",
    "    if n_found == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,c in enumerate(closest_sources):\n",
    "    # Create a 5-second light curve of each one. Note: each light curve can take many minutes\n",
    "    # to create.\n",
    "    print(\"Creating light curve for comparison star #\" + str(i+1) + \"...\")\n",
    "    lc_nuv = make_lightcurve(photon_files['NUV'][4], 'NUV', stepsz=5.,\n",
    "                             lc_filename=data_directory + 'nearest{0:d}_5s.csv'.format(i+1),\n",
    "                             skypos=[c['ra'], c['dec']], quiet=True, makefile=False)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot these light curves.\n",
    "comp_lc_1 = read_lc(data_directory + \"nearest1_5s.csv\")\n",
    "comp_lc_2 = read_lc(data_directory + \"nearest2_5s.csv\")\n",
    "comp_lc_3 = read_lc(data_directory + \"nearest3_5s.csv\")\n",
    "# Keep only those that have a decent amount of bin coverage.\n",
    "where_keep1 = np.where(np.asarray(comp_lc_1['expt']) > 3.)[0]\n",
    "where_keep2 = np.where(np.asarray(comp_lc_2['expt']) > 3.)[0]\n",
    "where_keep3 = np.where(np.asarray(comp_lc_3['expt']) > 3.)[0]\n",
    "times_1 = np.asarray(comp_lc_1['t0']-min(comp_lc_1['t0']))[where_keep1]\n",
    "times_2 = np.asarray(comp_lc_2['t0']-min(comp_lc_2['t0']))[where_keep2]\n",
    "times_3 = np.asarray(comp_lc_3['t0']-min(comp_lc_3['t0']))[where_keep3]\n",
    "fluxes_1 = np.asarray(comp_lc_1['flux_apcorrected'])[where_keep1]\n",
    "fluxes_2 = np.asarray(comp_lc_2['flux_apcorrected'])[where_keep2]\n",
    "fluxes_3 = np.asarray(comp_lc_3['flux_apcorrected'])[where_keep3]\n",
    "flux_err_1 = np.asarray(comp_lc_1['flux_err'])[where_keep1]\n",
    "flux_err_2 = np.asarray(comp_lc_2['flux_err'])[where_keep2]\n",
    "flux_err_3 = np.asarray(comp_lc_3['flux_err'])[where_keep3]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(16,14))\n",
    "ax1.errorbar(times_1, fluxes_1, yerr=flux_err_1, fmt='-ko')\n",
    "ax2.errorbar(times_2, fluxes_2, yerr=flux_err_2, fmt='-ko')\n",
    "ax3.errorbar(times_3, fluxes_3, yerr=flux_err_3, fmt='-ko')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check for any strong periodicity.\n",
    "lombscarg_1 = LombScargle(times_1, fluxes_1)\n",
    "frequency_1, power_1 = lombscarg_1.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "lombscarg_2 = LombScargle(times_2, fluxes_2)\n",
    "frequency_2, power_2 = lombscarg_2.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "lombscarg_3 = LombScargle(times_3, fluxes_3)\n",
    "frequency_3, power_3 = lombscarg_3.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(16,14))\n",
    "ax1.plot(1./frequency_1, power_1, '-k')\n",
    "ax2.plot(1./frequency_2, power_2, '-k')\n",
    "ax3.plot(1./frequency_3, power_3, '-k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_1 = np.asarray(frequency_1)\n",
    "frequency_2 = np.asarray(frequency_2)\n",
    "frequency_3 = np.asarray(frequency_3)\n",
    "power_1 = np.asarray(power_1)\n",
    "power_2 = np.asarray(power_2)\n",
    "power_3 = np.asarray(power_3)\n",
    "\n",
    "print(\"Comp. 1 Max Period = \" + str(1./frequency_1[np.argmax(power_1)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_1.false_alarm_probability(power_1.max())))\n",
    "print(\"Comp. 2 Max Period = \" + str(1./frequency_2[np.argmax(power_2)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_2.false_alarm_probability(power_2.max())))\n",
    "print(\"Comp. 3 Max Period = \" + str(1./frequency_3[np.argmax(power_3)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_3.false_alarm_probability(power_3.max())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No statistically significant peaks are detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now instead of finding the three closest stars, let's find the three closest stars that are\n",
    "# within 1 magnitude of GJ 65's peak brightness during the flare. This will test if there is\n",
    "# any systematic that only shows up under count rates comparable due to GJ 65 at peak brightness.\n",
    "gj65_brightest = max(lc_nuv[\"flux_apcorrected\"])\n",
    "gj65_brightest_mag = gt.counts2mag(gj65_brightest / 2.06e-16, \"NUV\")\n",
    "out = dt.get_mags('NUV', skypos[0], skypos[1], 0.6, gj65_brightest_mag + 1.)\n",
    "sources = np.asarray(dt.parse_unique_sources(out['ra'], out['dec'], margin=6./3600.))\n",
    "distances = np.asarray([mc.angularSeparation(skypos[0], skypos[1], x, y)*3600. for x,y in sources])\n",
    "sort_indexes = np.argsort(distances)\n",
    "sources = sources[sort_indexes]\n",
    "distances = distances[sort_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the closest similarly-bright stars, but ignore self-detections of GJ 65 in the MCAT.\n",
    "closest_sources = []\n",
    "n_found = 0\n",
    "for (ra, dec), dist in zip(sources, distances):\n",
    "    # If within a GALEX spatial resolution element, ignore (probably GJ 65 itself).\n",
    "    if dist > 6.:\n",
    "        closest_sources.append({'ra':ra, 'dec':dec, 'dist':dist})\n",
    "        n_found += 1\n",
    "    if n_found == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,c in enumerate(closest_sources):\n",
    "    # Create a 5-second light curve of each one. Note: each light curve can take many minutes\n",
    "    # to create.\n",
    "    print(\"Creating light curve for comparison star #\" + str(i+1) + \"...\")\n",
    "    lc_nuv = make_lightcurve(photon_files['NUV'][4], 'NUV', stepsz=5.,\n",
    "                             lc_filename=data_directory + 'brightest{0:d}_5s.csv'.format(i+1),\n",
    "                             skypos=[c['ra'], c['dec']], quiet=True, makefile=False)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot these light curves.\n",
    "bright_lc_1 = read_lc(data_directory + \"brightest1_5s.csv\")\n",
    "bright_lc_2 = read_lc(data_directory + \"brightest2_5s.csv\")\n",
    "bright_lc_3 = read_lc(data_directory + \"brightest3_5s.csv\")\n",
    "# Keep only those that have a decent amount of bin coverage.\n",
    "where_keep1 = np.where(np.asarray(bright_lc_1['expt']) > 3.)[0]\n",
    "where_keep2 = np.where(np.asarray(bright_lc_2['expt']) > 3.)[0]\n",
    "where_keep3 = np.where(np.asarray(bright_lc_3['expt']) > 3.)[0]\n",
    "times_1 = np.asarray(bright_lc_1['t0']-min(bright_lc_1['t0']))[where_keep1]\n",
    "times_2 = np.asarray(bright_lc_2['t0']-min(bright_lc_2['t0']))[where_keep2]\n",
    "times_3 = np.asarray(bright_lc_3['t0']-min(bright_lc_3['t0']))[where_keep3]\n",
    "fluxes_1 = np.asarray(bright_lc_1['flux_apcorrected'])[where_keep1]\n",
    "fluxes_2 = np.asarray(bright_lc_2['flux_apcorrected'])[where_keep2]\n",
    "fluxes_3 = np.asarray(bright_lc_3['flux_apcorrected'])[where_keep3]\n",
    "flux_err_1 = np.asarray(bright_lc_1['flux_err'])[where_keep1]\n",
    "flux_err_2 = np.asarray(bright_lc_2['flux_err'])[where_keep2]\n",
    "flux_err_3 = np.asarray(bright_lc_3['flux_err'])[where_keep3]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(16,14))\n",
    "ax1.errorbar(times_1, fluxes_1, yerr=flux_err_1, fmt='-ko')\n",
    "ax2.errorbar(times_2, fluxes_2, yerr=flux_err_2, fmt='-ko')\n",
    "ax3.errorbar(times_3, fluxes_3, yerr=flux_err_3, fmt='-ko')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's check for any strong periodicity.\n",
    "lombscarg_1 = LombScargle(times_1, fluxes_1)\n",
    "frequency_1, power_1 = lombscarg_1.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "lombscarg_2 = LombScargle(times_2, fluxes_2)\n",
    "frequency_2, power_2 = lombscarg_2.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "lombscarg_3 = LombScargle(times_3, fluxes_3)\n",
    "frequency_3, power_3 = lombscarg_3.autopower(minimum_frequency=0.01, maximum_frequency=0.1,\n",
    "                                                   samples_per_peak=20)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True, figsize=(16,14))\n",
    "ax1.plot(1./frequency_1, power_1, '-k')\n",
    "ax2.plot(1./frequency_2, power_2, '-k')\n",
    "ax3.plot(1./frequency_3, power_3, '-k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_1 = np.asarray(frequency_1)\n",
    "frequency_2 = np.asarray(frequency_2)\n",
    "frequency_3 = np.asarray(frequency_3)\n",
    "power_1 = np.asarray(power_1)\n",
    "power_2 = np.asarray(power_2)\n",
    "power_3 = np.asarray(power_3)\n",
    "\n",
    "print(\"Comp. 1 Max Period = \" + str(1./frequency_1[np.argmax(power_1)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_1.false_alarm_probability(power_1.max())))\n",
    "print(\"Comp. 2 Max Period = \" + str(1./frequency_2[np.argmax(power_2)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_2.false_alarm_probability(power_2.max())))\n",
    "print(\"Comp. 3 Max Period = \" + str(1./frequency_3[np.argmax(power_3)]) + \" sec\" +\n",
    "         \" with FAP = \" +\n",
    "      str(lombscarg_3.false_alarm_probability(power_3.max())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No statistically significant peaks are detected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
